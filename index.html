<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="main.css">
    <link rel="icon" type="image/x-icon" href="assets/favicon.png">
    <title>Humanoid Locomotion as Next Token Prediction</title>
</head>
<body>
<div id="video_grid">
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/golden_gate_marina.mov" type="video/mp4">
            </video>
            <div class="overlay">Marina Green</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/alta_plaza.mov" type="video/mp4">
            </video>
            <div class="overlay">Alta Plaza Park</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/balmy_alley_zoom_in.mov" type="video/mp4">
            </video>
            <div class="overlay">Balmy Alley</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/bay_bridge.mov" type="video/mp4">
            </video>
            <div class="overlay">Bay Bridge</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/bay_bridge_side_view.mov" type="video/mp4">
            </video>
            <div class="overlay">Bay Trail</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/city_hall.mov" type="video/mp4">
            </video>
            <div class="overlay">City Hall</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/ferry_building.mov" type="video/mp4">
            </video>
            <div class="overlay">Ferry Building</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/ferry_building_backview.mov" type="video/mp4">
            </video>
            <div class="overlay">Market Street</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/ferry_building_front.mov" type="video/mp4">
            </video>
            <div class="overlay">Harry Bridges Plaza</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/painted_ladies.mov" type="video/mp4">
            </video>
            <div class="overlay">Painted Ladies</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/palace_fine_art.mov" type="video/mp4">
            </video>
            <div class="overlay">Palace of Fine Arts</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/rough_walk.mov" type="video/mp4">
            </video>
            <div class="overlay">Crissy Field</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/sand_walk_people.mov" type="video/mp4">
            </video>
            <div class="overlay">Crissy Field Beach</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/street_view_v3.mov" type="video/mp4">
            </video>
            <div class="overlay">Washington St</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/tram.mov" type="video/mp4">
            </video>
            <div class="overlay">California St</div>
        </div>
    </div>
    <div class="video_wrapper">
        <div class="video_container">
            <video autoplay muted playsinline loop>
                <source src="assets/grid/bart.mov" type="video/mp4">
            </video>
            <div class="overlay">Embarcadero Bart</div>
        </div>
    </div>
</div>
<div id="title_slide">
    <div class="title_left">
        <h1>Humanoid Locomotion as <br> Next Token Prediction</h1>
        <div class="author-container-1">
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~ilija/">Ilija Radosavovic</a></div>
            <div class="grid-item"><a href="https://bikezhang106.github.io/">Bike Zhang</a></div>
            <div class="grid-item"><a href="https://bfshi.github.io/">Baifeng Shi</a></div>
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~jathushan/">Jathushan Rajasegaran</a></div>
            <div class="grid-item"><a href="">Sarthak Kamat</a></div>
        </div>
        <div class="author-container-2">
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a></div>
            <div class="grid-item"><a href="https://hybrid-robotics.berkeley.edu/koushil/">Koushil Sreenath</a></div>
            <div class="grid-item"><a href="http://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a></div>
        </div>
        <div class="mobile-author-container-1">
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~ilija/">Ilija Radosavovic</a></div>
            <div class="grid-item"><a href="https://bikezhang106.github.io/">Bike Zhang</a></div>
            <div class="grid-item"><a href="https://bfshi.github.io/">Baifeng Shi</a></div>
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~jathushan/">Jathushan Rajasegaran</a></div>
        </div>
        <div class="mobile-author-container-2">
            <div class="grid-item"><a href="">Sarthak Kamat</a></div>
            <div class="grid-item"><a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a></div>
            <div class="grid-item"><a href="https://hybrid-robotics.berkeley.edu/koushil/">Koushil Sreenath</a></div>
            <div class="grid-item"><a href="http://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a></div>
        </div>
        <div class="berkeley">
            <p>University of California, Berkeley</p>
        </div>
        <div class="button-container">
            <a href="https://arxiv.org/abs/2402.19469" class="button">Paper</a>
            <a href="https://www.youtube.com/watch?v=ok4DHssENE4" class="button">Video</a>
        </div>

        <br>

        <div id="abstract" class="grid-container">
            <p>
                We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories.
            </p>
        </div>
    </div>
</div>
<hr class="rounded">
<div id="overview">

    <h1>Humanoid Locomotion as Next Token Prediction</h1>

    <p>
        We cast real-world humanoid control as a data modeling problem over a large collections of sensorimotor trajectories. Like in language, we train a general transformer model to autoregressively predict shifted input sequences. In contrast to language, the nature of data in robotics is different. It is high-dimensional, contains multiple sensory modalities, and actions. We tokenize the input trajectories and train a causal transformer model to predict shifted tokens. Importantly, we predict complete input sequences, including both sensory and action tokens. In other words, we are modeling the joint data distribution as opposed to the conditional action distribution.
    </p>

    <div class="barplot">
        <div class="image_container">
            <img src="assets/overview.png">
            <div class="caption" style="margin-top: 0.0vw">
                <p> We collect a dataset on trajectories, train a transformer model by autoregressive prediction, and deploy it in San Francisco zero-shot.</p>
            </div>
        </div>
    </div>

    <h1>A General Framework for Training with Missing Data</h1>

    <p>
        In the discussion so far we have assumed that each trajectory is a sequence of observations and actions. Next, we show how our framework can be generalized to sequences with missing modalities, like trajectories extracted from human videos that do not have actions. Suppose we are given a trajectory of observations without the actions. Our key insight is that we can treat a trajectory without actions like a regular trajectory with actions masked. This trajectory now has the same format as our regular trajectories and thus can be processed in a unified way. We ignore the loss for the predictions that correspond to the masked part of inputs.
    </p>

    <div class="barplot">
        <div class="image_container">
            <img src="assets/missing_data.png">
            <div class="caption" style="margin-top: 0.0vw">
                <p>Our approach enables us to leverage trajectories with or without actions in a unified way.</p>
            </div>
        </div>
    </div>

    <h1>A Dataset of Trajectories</h1>

    <p>
        Our approach motivates building a dataset of trajectories for training our model. Our dataset includes trajectories from four different sources: (i) prior neural network policies, (ii) model-based controllers, (iii) human motion capture, and (iv) human videos from YouTube. An illustration of different data sources is shown below. Different sources strike a different tradeoff between the richness of information and scale. For example, trajectories from neural network policies provide complete information including the actions. Trajectories from the model-based controller contain observations from the same robot morphology without the actions. MoCap trajectories of humans come from a different morphology without the actions. Finally, trajectories recovered from YouTube videos of humans can be seen as large scale but noisy MoCap.
    </p>

    <div class="barplot">
        <div class="image_container">
            <img src="assets/data.png">
            <div class="caption" style="margin-top: 0.0vw">
                <p>To train our model, we construct a dataset of trajectories coming from four different sources.</p>
            </div>
        </div>
    </div>

    <h1>A Humanoid that Walks in San Francisco</h1>

    <p>
        We deploy our policy to various locations in San Francisco over the course of one week. A few example videos are shown below. We find that our policy can walk over different surfaces including walkways, concrete, asphalt, plazas, and sanded roads. We find that our policy follows omnidirectional velocity commands well, and enables deployment in a challenging city environment.
    </p>
    <br>

    <div class="allegroupper">
        <video autoplay muted playsinline loop preload="metadata">
            <source src="assets/grid/alta_plaza.mov" type="video/mp4">
        </video>
        <video autoplay muted playsinline loop preload="metadata">
            <source src="assets/grid/golden_gate_marina.mov" type="video/mp4">
        </video>
    </div>
    <div class="allegrolower">
        <div class="video_container">
            <video autoplay muted playsinline loop preload="metadata">
                <source src="assets/grid/city_hall.mov" type="video/mp4">
            </video>
            <div class="caption">
                <p>Walking in different locations in San Francisco</p>
            </div>
        </div>
        <div class="video_container">
            <video autoplay muted playsinline loop preload="metadata">
                <source src="assets/grid/palace_fine_art.mov" type="video/mp4">
            </video>
        </div>
    </div>

    <h1>BibTeX</h1>
    <p class="bibtex">
        @article{TokenHumanoid2024,<br>
        &nbsp;&nbsp;title={Humanoid Locomotion as Next Token Prediction},<br>
        &nbsp;&nbsp;author={Ilija Radosavovic and Bike Zhang and Baifeng Shi and Jathushan Rajasegaran and Sarthak Kamat and Trevor Darrell and Koushil Sreenath and Jitendra Malik},<br>
        &nbsp;&nbsp;year={2024},<br>
        &nbsp;&nbsp;journal={arXiv:2402.19469}<br>
        }
    </p>
</div>
<script type="text/javascript">
    /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
    document.querySelector('video').defaultPlaybackRate = 1.0;
    document.querySelector('video').play();

    var videos =document.querySelectorAll('video');
    for (var i=0;i<1;i++)
    {
        videos[i].playbackRate = 1.0;
    }
</script>
<script>
    /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
    var videos = document.getElementsByTagName("video");

    function checkScroll() {
        var fraction = 0.5; // Play when 70% of the player is visible.

        for(var i = 0; i < 1; i++) {  // only apply to the first video

            var video = videos[i];

            var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                b = y + h, //bottom
                visibleX, visibleY, visible;

            visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
            visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

            visible = visibleX * visibleY / (w * h);

            if (visible > fraction) {
                video.play();
            } else {
                video.pause();
            }

        }

    }
    window.addEventListener('scroll', checkScroll, false);
    window.addEventListener('resize', checkScroll, false);
</script>
<script>
    // Function to check if the user is on a mobile device
    function isMobileDevice() {
        return /Mobi|Android/i.test(navigator.userAgent);
    }

    // If the user is on a mobile device, disable autoplay
    if (isMobileDevice()) {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
            video.autoplay = false;
        });
    }
</script>
<script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
        type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
        crossorigin="anonymous"></script>
<script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
        type="text/javascript"></script>
</body>
</html>
